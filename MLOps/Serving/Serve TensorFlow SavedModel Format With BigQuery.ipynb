{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f122f911",
   "metadata": {},
   "source": [
    "![tracker](https://us-central1-vertex-ai-mlops-369716.cloudfunctions.net/pixel-tracking?path=statmike%2Fvertex-ai-mlops%2FMLOps%2FServing&file=Serve+TensorFlow+SavedModel+Format+With+BigQuery.ipynb)\n",
    "<!--- header table --->\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/statmike/vertex-ai-mlops/blob/main/MLOps/Serving/Serve%20TensorFlow%20SavedModel%20Format%20With%20BigQuery.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\">\n",
    "      <br>Run in<br>Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2Fstatmike%2Fvertex-ai-mlops%2Fmain%2FMLOps%2FServing%2FServe%2520TensorFlow%2520SavedModel%2520Format%2520With%2520BigQuery.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\">\n",
    "      <br>Run in<br>Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/statmike/vertex-ai-mlops/blob/main/MLOps/Serving/Serve%20TensorFlow%20SavedModel%20Format%20With%20BigQuery.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      <br>View on<br>GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/statmike/vertex-ai-mlops/main/MLOps/Serving/Serve%20TensorFlow%20SavedModel%20Format%20With%20BigQuery.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      <br>Open in<br>Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cba717-4026-4176-b22a-fa3800a73be4",
   "metadata": {},
   "source": [
    "# Serve TensorFlow SavedModel Format With BigQuery\n",
    "\n",
    "Serve model predictions inside BigQuery for [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model) format.\n",
    "\n",
    "BigQuery has a vast set of capabilities related to ML known as BigQuery ML (or BQML for short).\n",
    "- [BigQuery ML](https://cloud.google.com/bigquery/docs/bqml-introduction)\n",
    "- [BigQuery ML user journey for models](https://cloud.google.com/bigquery/docs/e2e-journey)\n",
    "\n",
    "> For many workflow examples with BigQuery ML check out the [Framework Workflows/BQML](../../Framework%20Workflows/BQML/readme.md) folder in this repository!\n",
    "\n",
    "With these capabilities you can train models directly in BigQuery, import model files for serving inside BigQuery, or connect to remote models for use from BigQuery.\n",
    "\n",
    "This workflow focuses on importing a model, specifically a TensorFlow SavedModel format model as covered in [this documentation page](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-tensorflow). \n",
    "\n",
    "There are limits to cover prior to getting started:\n",
    "- not all BigQuery ML functions will work with imported models\n",
    "- Models are limited to sizes under 450MB\n",
    "- Model files must be in GCS, int he SavedModel format, use a GraphDef version of atleast 20, only use core TensorFlow operation (no tf.contrib operations), no RaggedTensors\n",
    "- see a [full list here](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-tensorflow#limitations)\n",
    "\n",
    "What this workflow does:\n",
    "- Prepare the TensorFlow SavedModel files created in this repository by another workflow: [Keras With JAX Overview](../../Framework%20Workflows/Keras/Keras%20With%20JAX%20Overview.ipynb)\n",
    "- Setup BigQuery Dataset\n",
    "- Create Models with the imported model files\n",
    "- Serve predictions with `ML.PREDICT` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5cf661-e0d6-424a-8f91-7c464c99d4c5",
   "metadata": {
    "id": "od_UkDpvRmgD"
   },
   "source": [
    "---\n",
    "## Colab Setup\n",
    "\n",
    "When running this notebook in [Colab](https://colab.google/) or [Colab Enterprise](https://cloud.google.com/colab/docs/introduction), this section will authenticate to GCP (follow prompts in the popup) and set the current project for the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc7fec0-3888-48f3-bfa9-49f5b70f3ed5",
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1683726184843,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "8UO9FnqyKBlF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'statmike-mlops-349915' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c408e9ef-2536-414a-b17e-72a825f14cd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68869,
     "status": "ok",
     "timestamp": 1683726253709,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "N98-KK7LRkjm",
    "outputId": "09ec5008-0def-4e1a-c349-c598ee752f78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa0d5dd-9f76-45bf-9810-09786d905264",
   "metadata": {},
   "source": [
    "---\n",
    "## Installs and API Enablement\n",
    "\n",
    "The clients packages may need installing in this environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6904753-9788-4c71-8b46-5a3070b9aacb",
   "metadata": {},
   "source": [
    "### Installs (If Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7bad5fe5-ec6a-4d1c-943e-a6702177ae6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.bigquery', 'google-cloud-bigquery'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage'),\n",
    "    ('numpy', 'numpy'),\n",
    "    ('tensorflow', 'tensorflow'),\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d650c-aade-4a33-8564-947e8fcec254",
   "metadata": {},
   "source": [
    "### API Enablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75802b90-082d-4fca-b7df-0016202ed4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7db42-c2ad-4f4a-bc74-c32dabb2b405",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76a7882-5d4b-4158-a213-62b0d5ad13f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "    IPython.display.display(IPython.display.Markdown(\"\"\"<div class=\\\"alert alert-block alert-warning\\\">\n",
    "        <b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. The previous cells do not need to be run again⚠️</b>\n",
    "        </div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ddf77-ea97-4703-8db8-60d009a63e50",
   "metadata": {
    "id": "appt8-yVRtJ1"
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92101d5e-20ee-4c3c-9d68-5327b5808ecd",
   "metadata": {
    "id": "63mx2EozRxFP"
   },
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa208e98-2849-4d5a-aaff-9fc8f864b7c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1683726390544,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "xzcoXjM5Rky5",
    "outputId": "b3bdcbc1-70d5-472e-aea2-42c74a42efde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "096f118a-ee93-4da1-85dc-58c55b98a037",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683726390712,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "IxWrFtqYMfku",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'mlops-serving'\n",
    "EXPERIMENT = 'bigquery-tensorflow'\n",
    "\n",
    "# gcs bucket name\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "\n",
    "# Data source for this series of notebooks: Described above\n",
    "BQ_SOURCE = 'bigquery-public-data.ml_datasets.ulb_fraud_detection'\n",
    "\n",
    "# make this the BigQuery Project / Dataset / Table prefix to store results\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = SERIES.replace('-', '_')\n",
    "BQ_TABLE = SERIES\n",
    "BQ_REGION = REGION[0:2] # use a multi region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64a864-6d64-4365-9ece-9688166bc945",
   "metadata": {
    "id": "LuajVwCiO6Yg"
   },
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a69404fc-8fb8-4b61-ab8f-a35e65bad355",
   "metadata": {
    "executionInfo": {
     "elapsed": 17761,
     "status": "ok",
     "timestamp": 1683726409304,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "LVC7zzSLRk2C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import python package\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# BigQuery\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# gcs\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e02c32-d233-43f6-83e1-1370f5d582e9",
   "metadata": {
    "id": "EyAVFG9TO9H-"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a2b384a-f757-49d8-bb29-54e3582b55c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1683726409306,
     "user": {
      "displayName": "Mike Henderson",
      "userId": "07691629187611687318"
     },
     "user_tz": 240
    },
    "id": "L0RPE13LOZce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bigquery client\n",
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "\n",
    "# gcs client\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bucket = gcs.bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2477b0eb-f046-4609-a840-efaad1b946fd",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77d9432d-e055-4f84-81e2-32028479adf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = f\"files/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab50f01-677a-4401-a275-0e7b50a49c99",
   "metadata": {},
   "source": [
    "Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed4d6540-d97a-409d-9950-801b0e1121cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc22de71-d15b-4dc9-aaef-6c64a57b9483",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Files For Examples\n",
    "\n",
    "The TensorFlow SavedModel files used here were created in this repository by another workflow: [Keras With JAX Overview](../../Framework%20Workflows/Keras/Keras%20With%20JAX%20Overview.ipynb).  That workflow does not need to be run because the resulting model files are within this repository.  If this notebook is being used separate from a full clone of the repository then this section will fetch the files from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1696f59-fae6-454a-be2e-b007a56b0ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = '../../Framework Workflows/Keras/files/keras-overview/tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1eb1c34-f717-4557-8a73-e4b82c29d242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Found in folder `../../Framework Workflows/Keras/files/keras-overview/tensorflow`\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(local_dir):\n",
    "    print('Retrieving files...')\n",
    "    local_dir = DIR\n",
    "    parent_dir = os.path.dirname(local_dir)\n",
    "    temp_dir = os.path.join(parent_dir, 'temp')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    !git clone https://www.github.com/statmike/vertex-ai-mlops {temp_dir}/vertex-ai-mlops\n",
    "    shutil.copytree(f'{temp_dir}/vertex-ai-mlops/Applied GenAI/Embeddings/files/embeddings-api', local_dir)\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'Files are now in folder `{local_dir}`')\n",
    "else:\n",
    "    print(f'Files Found in folder `{local_dir}`')             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca6c524f-98f3-4910-b430-914b319e1b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/embedding_model/fingerprint.pb\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/embedding_model/saved_model.pb\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/embedding_model/variables/variables.index\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/embedding_model/variables/variables.data-00000-of-00001\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/stacked_model/fingerprint.pb\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/stacked_model/saved_model.pb\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/stacked_model/variables/variables.index\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/stacked_model/variables/variables.data-00000-of-00001\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/final_model/fingerprint.pb\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/final_model/saved_model.pb\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/final_model/variables/variables.index\n",
      "../../Framework Workflows/Keras/files/keras-overview/tensorflow/final_model/variables/variables.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "for root, _, files in os.walk(local_dir):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "170ac1bf-187e-42a0-94f3-07a7cc9b7a08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/embedding_model/fingerprint.pb to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/embedding_model/fingerprint.pb\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/embedding_model/saved_model.pb to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/embedding_model/saved_model.pb\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/embedding_model/variables/variables.index to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/embedding_model/variables/variables.index\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/embedding_model/variables/variables.data-00000-of-00001 to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/embedding_model/variables/variables.data-00000-of-00001\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/stacked_model/fingerprint.pb to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/stacked_model/fingerprint.pb\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/stacked_model/saved_model.pb to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/stacked_model/saved_model.pb\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/stacked_model/variables/variables.index to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/stacked_model/variables/variables.index\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/stacked_model/variables/variables.data-00000-of-00001 to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/stacked_model/variables/variables.data-00000-of-00001\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/final_model/fingerprint.pb to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/final_model/fingerprint.pb\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/final_model/saved_model.pb to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/final_model/saved_model.pb\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/final_model/variables/variables.index to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/final_model/variables/variables.index\n",
      "Copying file://../../Framework Workflows/Keras/files/keras-overview/tensorflow/final_model/variables/variables.data-00000-of-00001 to gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/final_model/variables/variables.data-00000-of-00001\n",
      "  Completed files 12/12 | 327.9kiB/327.9kiB                                    \n",
      "\n",
      "Average throughput: 1.7MiB/s\n"
     ]
    }
   ],
   "source": [
    "!gcloud storage cp -r '{local_dir}' gs://{GCS_BUCKET}/{SERIES}/{EXPERIMENT}/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9ec57a7a-a38a-497d-a71e-f03126c080b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_signature(uri):\n",
    "    loaded_model = tf.saved_model.load(uri)\n",
    "    signatures = loaded_model.signatures\n",
    "    print(f\"Available Signatures for: {uri}\")\n",
    "    for signature_name, signature_fn in signatures.items():\n",
    "        print(f\"\\nSignature Name: {signature_name}\")\n",
    "        print(\"\\nInputs:\")\n",
    "        if hasattr(signature_fn, 'structured_input_signature') and signature_fn.structured_input_signature:\n",
    "            for input_name, input_spec in signature_fn.structured_input_signature[1].items():\n",
    "                print(f\"  {input_name}:\")\n",
    "                print(f\"    dtype: {input_spec.dtype}\")\n",
    "                print(f\"    shape: {input_spec.shape}\")\n",
    "        else:\n",
    "            print(\"  No structured input signature available.\")\n",
    "        print(\"\\nOutputs:\")\n",
    "        if hasattr(signature_fn, \"structured_outputs\") and signature_fn.structured_outputs:\n",
    "            for output_name, output_spec in signature_fn.structured_outputs.items():\n",
    "                print(f\"  {output_name}:\")\n",
    "                print(f\"    dtype: {output_spec.dtype}\")\n",
    "                print(f\"    shape: {output_spec.shape}\")\n",
    "        else:\n",
    "            print(\"  No structured output signature available.\")\n",
    "            \n",
    "    def check_xla(signatures):\n",
    "        try:\n",
    "            concrete_func = signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "            graph_def = concrete_func.graph.as_graph_def()\n",
    "            \n",
    "            def _check_node(node):\n",
    "                if \"XlaCallModule\" in node.op:\n",
    "                    return True\n",
    "                for attr in node.attr.values():\n",
    "                    if attr.func:\n",
    "                        func_name = attr.func.name\n",
    "                        for func in graph_def.library.function:\n",
    "                            if func.signature.name == func_name:\n",
    "                                for func_node in func.node_def:\n",
    "                                    if _check_node(func_node):\n",
    "                                        return True\n",
    "                return False\n",
    "            \n",
    "            for node in graph_def.node:\n",
    "                if _check_node(node):\n",
    "                    return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f'Error checking XLA: {e}')\n",
    "            return None\n",
    "\n",
    "    has_xla = check_xla(signatures)\n",
    "        \n",
    "    if has_xla:\n",
    "        print('XLA Detected - Conversion Required for BQML.')\n",
    "    else:\n",
    "        print('XLA Not Detected - Model Should Work With BQML')\n",
    "            \n",
    "    print('\\n\\n')\n",
    "    \n",
    "    return has_xla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9bd3df40-eb78-460c-af58-56dbef404638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlops-serving/bigquery-tensorflow/models/embedding_model/fingerprint.pb',\n",
       " 'mlops-serving/bigquery-tensorflow/models/embedding_model/saved_model.pb',\n",
       " 'mlops-serving/bigquery-tensorflow/models/embedding_model/variables/variables.data-00000-of-00001',\n",
       " 'mlops-serving/bigquery-tensorflow/models/embedding_model/variables/variables.index',\n",
       " 'mlops-serving/bigquery-tensorflow/models/final_model/fingerprint.pb',\n",
       " 'mlops-serving/bigquery-tensorflow/models/final_model/saved_model.pb',\n",
       " 'mlops-serving/bigquery-tensorflow/models/final_model/variables/variables.data-00000-of-00001',\n",
       " 'mlops-serving/bigquery-tensorflow/models/final_model/variables/variables.index',\n",
       " 'mlops-serving/bigquery-tensorflow/models/stacked_model/fingerprint.pb',\n",
       " 'mlops-serving/bigquery-tensorflow/models/stacked_model/saved_model.pb',\n",
       " 'mlops-serving/bigquery-tensorflow/models/stacked_model/variables/variables.data-00000-of-00001',\n",
       " 'mlops-serving/bigquery-tensorflow/models/stacked_model/variables/variables.index']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[blob.name for blob in bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}/models')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a6cc16b2-7780-4906-b6a8-f3694a6a5fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_109431) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_106252) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Signatures for: gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/embedding_model\n",
      "\n",
      "Signature Name: serve\n",
      "\n",
      "Inputs:\n",
      "  keras_tensor_113:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "\n",
      "Outputs:\n",
      "  output_0:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 4)\n",
      "\n",
      "Signature Name: serving_default\n",
      "\n",
      "Inputs:\n",
      "  keras_tensor_113:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "\n",
      "Outputs:\n",
      "  output_0:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 4)\n",
      "XLA Detected - Conversion Required for BQML.\n",
      "\n",
      "\n",
      "\n",
      "Model has XLA and will not work with BQML.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_108012) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Signatures for: gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/final_model\n",
      "\n",
      "Signature Name: serve\n",
      "\n",
      "Inputs:\n",
      "  input_layer:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "\n",
      "Outputs:\n",
      "  normalized_reconstruction:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "  encoded:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 4)\n",
      "  denormalized_reconstruction:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "  normalized_RMSE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  normalized_MSLE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  denormalized_MAE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  denormalized_MSLE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  normalized_MAE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  normalized_MSE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  denormalized_MSE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  normalized_reconstruction_errors:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "  denormalized_RMSE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  denormalized_reconstruction_errors:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "\n",
      "Signature Name: serving_default\n",
      "\n",
      "Inputs:\n",
      "  input_layer:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "\n",
      "Outputs:\n",
      "  normalized_reconstruction:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "  encoded:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 4)\n",
      "  denormalized_reconstruction:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "  normalized_RMSE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  normalized_MSLE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  denormalized_MAE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  denormalized_MSLE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  normalized_MAE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  normalized_MSE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  denormalized_MSE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  normalized_reconstruction_errors:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "  denormalized_RMSE:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None,)\n",
      "  denormalized_reconstruction_errors:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "XLA Detected - Conversion Required for BQML.\n",
      "\n",
      "\n",
      "\n",
      "Model has XLA and will not work with BQML.\n",
      "Available Signatures for: gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/stacked_model\n",
      "\n",
      "Signature Name: serve\n",
      "\n",
      "Inputs:\n",
      "  keras_tensor_28:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "\n",
      "Outputs:\n",
      "  output_0:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "\n",
      "Signature Name: serving_default\n",
      "\n",
      "Inputs:\n",
      "  keras_tensor_28:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "\n",
      "Outputs:\n",
      "  output_0:\n",
      "    dtype: <dtype: 'float32'>\n",
      "    shape: (None, 30)\n",
      "XLA Detected - Conversion Required for BQML.\n",
      "\n",
      "\n",
      "\n",
      "Model has XLA and will not work with BQML.\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for blob in bucket.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}/models'):\n",
    "    if blob.name.endswith('saved_model.pb'):\n",
    "        uri = f\"gs://{bucket.name}/{blob.name.split('/saved_model.pb')[0]}\"\n",
    "        has_xla = get_signature(uri)\n",
    "        if has_xla:\n",
    "            print('Model has XLA and will not work with BQML.')\n",
    "        else:\n",
    "            models.append(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19813452-ebe0-4d31-9998-be2733828990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62427d35-3e69-42c6-8f51-ca545a23d270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe487122-c21e-496b-adf0-1ffb5e17ad28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2094d-f75e-4842-a8af-517521967de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7b5472a-98f1-4bec-b80e-5e5eb6515ac1",
   "metadata": {},
   "source": [
    "---\n",
    "## BigQuery Model Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4f675-979d-4c4c-97a2-40fc212e9490",
   "metadata": {},
   "source": [
    "### Create/Recall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6dcd91f-fa4d-4cfa-94cc-92e2175f32bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = bigquery.Dataset(f\"{BQ_PROJECT}.{BQ_DATASET}\")\n",
    "dataset.location = BQ_REGION\n",
    "bq_dataset = bq.create_dataset(dataset, exists_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c919aa3-6a8e-4738-9519-7f4d7d796fa9",
   "metadata": {},
   "source": [
    "### Create/Recall Table With Preparation For ML\n",
    "\n",
    "Copy the data from the source while adding columns:\n",
    "- `transaction_id` as a unique identify for the row\n",
    "    - Use the `GENERATE_UUID()` function\n",
    "- `splits` column to randomly assign rows to 'TRAIN\", \"VALIDATE\" and \"TEST\" groups\n",
    "    - stratified sampling within the levels of `class` by first assigning row numbers within the levels of `class` then using the with a CASE statment to assign the `splits` level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "db962852-cb4c-436b-a8de-aea409e7bafa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.537"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = bq.query(f\"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "#CREATE TABLE IF NOT EXISTS \n",
    "    `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` AS\n",
    "WITH\n",
    "    add_id AS (\n",
    "        SELECT *,\n",
    "            GENERATE_UUID() transaction_id,\n",
    "            ROW_NUMBER() OVER (PARTITION BY class ORDER BY RAND()) as rn\n",
    "            FROM `{BQ_SOURCE}`\n",
    "    )\n",
    "SELECT * EXCEPT(rn),\n",
    "    CASE \n",
    "        WHEN rn <= 0.8 * COUNT(*) OVER (PARTITION BY class) THEN 'TRAIN'\n",
    "        WHEN rn <= 0.9 * COUNT(*) OVER (PARTITION BY class) THEN 'VALIDATE'\n",
    "        ELSE 'TEST'\n",
    "    END AS splits\n",
    "FROM add_id\n",
    "\"\"\")\n",
    "job.result()\n",
    "(job.ended-job.started).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5e900c1a-a3f5-436e-9455-0e2f08506faa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56723.0</td>\n",
       "      <td>-0.207067</td>\n",
       "      <td>0.635891</td>\n",
       "      <td>1.468863</td>\n",
       "      <td>-0.701046</td>\n",
       "      <td>-0.105003</td>\n",
       "      <td>-1.086781</td>\n",
       "      <td>0.761288</td>\n",
       "      <td>-0.344025</td>\n",
       "      <td>0.074596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064738</td>\n",
       "      <td>0.395483</td>\n",
       "      <td>-0.354941</td>\n",
       "      <td>0.769522</td>\n",
       "      <td>-0.371157</td>\n",
       "      <td>-0.217015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>316fd6dc-ee5b-4d04-99bd-2670821fcf35</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18098.0</td>\n",
       "      <td>1.165687</td>\n",
       "      <td>0.409860</td>\n",
       "      <td>1.019294</td>\n",
       "      <td>2.044608</td>\n",
       "      <td>-0.154006</td>\n",
       "      <td>0.177514</td>\n",
       "      <td>-0.224623</td>\n",
       "      <td>-0.042588</td>\n",
       "      <td>0.955046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160420</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.119947</td>\n",
       "      <td>0.739299</td>\n",
       "      <td>-0.063692</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>08830e11-2791-4991-8b8e-b857184147b6</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126046.0</td>\n",
       "      <td>2.135118</td>\n",
       "      <td>-0.045835</td>\n",
       "      <td>-3.814614</td>\n",
       "      <td>-0.615515</td>\n",
       "      <td>3.225990</td>\n",
       "      <td>2.696986</td>\n",
       "      <td>0.376352</td>\n",
       "      <td>0.435114</td>\n",
       "      <td>-0.307914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139735</td>\n",
       "      <td>0.803295</td>\n",
       "      <td>0.719782</td>\n",
       "      <td>0.744174</td>\n",
       "      <td>-0.104081</td>\n",
       "      <td>-0.100148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5c021261-b2a7-4549-8bc1-60dea2645acc</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127177.0</td>\n",
       "      <td>-1.476899</td>\n",
       "      <td>0.364446</td>\n",
       "      <td>2.242367</td>\n",
       "      <td>3.191857</td>\n",
       "      <td>1.834470</td>\n",
       "      <td>2.275351</td>\n",
       "      <td>-0.604366</td>\n",
       "      <td>0.867248</td>\n",
       "      <td>-1.501472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490477</td>\n",
       "      <td>-1.634986</td>\n",
       "      <td>0.272646</td>\n",
       "      <td>0.484312</td>\n",
       "      <td>0.018321</td>\n",
       "      <td>0.086282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>f0893feb-a359-469c-a9a7-0dff1008211b</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99389.0</td>\n",
       "      <td>-0.469834</td>\n",
       "      <td>1.381115</td>\n",
       "      <td>2.227870</td>\n",
       "      <td>2.991743</td>\n",
       "      <td>0.625074</td>\n",
       "      <td>0.534667</td>\n",
       "      <td>0.389924</td>\n",
       "      <td>0.085466</td>\n",
       "      <td>-0.041547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248184</td>\n",
       "      <td>-0.135584</td>\n",
       "      <td>-0.292904</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.141803</td>\n",
       "      <td>0.167097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10c9c140-e3a5-4548-963a-70b3eaf5760b</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   56723.0 -0.207067  0.635891  1.468863 -0.701046 -0.105003 -1.086781   \n",
       "1   18098.0  1.165687  0.409860  1.019294  2.044608 -0.154006  0.177514   \n",
       "2  126046.0  2.135118 -0.045835 -3.814614 -0.615515  3.225990  2.696986   \n",
       "3  127177.0 -1.476899  0.364446  2.242367  3.191857  1.834470  2.275351   \n",
       "4   99389.0 -0.469834  1.381115  2.227870  2.991743  0.625074  0.534667   \n",
       "\n",
       "         V7        V8        V9  ...       V23       V24       V25       V26  \\\n",
       "0  0.761288 -0.344025  0.074596  ... -0.064738  0.395483 -0.354941  0.769522   \n",
       "1 -0.224623 -0.042588  0.955046  ...  0.160420  0.078300  0.119947  0.739299   \n",
       "2  0.376352  0.435114 -0.307914  ... -0.139735  0.803295  0.719782  0.744174   \n",
       "3 -0.604366  0.867248 -1.501472  ... -0.490477 -1.634986  0.272646  0.484312   \n",
       "4  0.389924  0.085466 -0.041547  ... -0.248184 -0.135584 -0.292904  0.005450   \n",
       "\n",
       "        V27       V28  Amount  Class                        transaction_id  \\\n",
       "0 -0.371157 -0.217015     0.0      0  316fd6dc-ee5b-4d04-99bd-2670821fcf35   \n",
       "1 -0.063692  0.004084     0.0      0  08830e11-2791-4991-8b8e-b857184147b6   \n",
       "2 -0.104081 -0.100148     0.0      0  5c021261-b2a7-4549-8bc1-60dea2645acc   \n",
       "3  0.018321  0.086282     0.0      0  f0893feb-a359-469c-a9a7-0dff1008211b   \n",
       "4  0.141803  0.167097     0.0      0  10c9c140-e3a5-4548-963a-70b3eaf5760b   \n",
       "\n",
       "   splits  \n",
       "0    TEST  \n",
       "1    TEST  \n",
       "2    TEST  \n",
       "3    TEST  \n",
       "4    TEST  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sample = bq.query(f'SELECT * FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` LIMIT 5').to_dataframe()\n",
    "raw_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88374b7b-142f-4afa-950a-fccffcf0192a",
   "metadata": {},
   "source": [
    "### Add A Column For Feature Array\n",
    "\n",
    "Combine all the features into a single column, an array of floats, for easier inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b68ff74e-fbac-44b5-8f0f-075703662d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time',\n",
       " 'V1',\n",
       " 'V2',\n",
       " 'V3',\n",
       " 'V4',\n",
       " 'V5',\n",
       " 'V6',\n",
       " 'V7',\n",
       " 'V8',\n",
       " 'V9',\n",
       " 'V10',\n",
       " 'V11',\n",
       " 'V12',\n",
       " 'V13',\n",
       " 'V14',\n",
       " 'V15',\n",
       " 'V16',\n",
       " 'V17',\n",
       " 'V18',\n",
       " 'V19',\n",
       " 'V20',\n",
       " 'V21',\n",
       " 'V22',\n",
       " 'V23',\n",
       " 'V24',\n",
       " 'V25',\n",
       " 'V26',\n",
       " 'V27',\n",
       " 'V28',\n",
       " 'Amount']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [col for col in raw_sample.columns if col not in ['splits', 'transaction_id', 'Class']]\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d937189e-ff96-4270-b59f-41b8b15ab055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.676"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` AS\n",
    "SELECT\n",
    "    t.*, # EXCEPT(features_array),\n",
    "    ARRAY[\n",
    "        {', '.join(feature_columns)}\n",
    "    ] AS features_array\n",
    "FROM\n",
    "    `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` AS t;\n",
    "\"\"\"\n",
    "\n",
    "job = bq.query(query)\n",
    "job.result()\n",
    "(job.ended - job.started).total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb14eb-dace-4f6b-8669-c741fe96d3ad",
   "metadata": {},
   "source": [
    "### Review the number of records for each level of `Class` for each of the data splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c32dcf5b-0ce9-456e-ab2f-9a845d978da2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>splits</th>\n",
       "      <th>class</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>10.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>79.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>9.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST</td>\n",
       "      <td>0</td>\n",
       "      <td>28432</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "      <td>227452</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>28431</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     splits  class   count  percentage\n",
       "0      TEST      1      50       10.16\n",
       "1     TRAIN      1     393       79.88\n",
       "2  VALIDATE      1      49        9.96\n",
       "3      TEST      0   28432       10.00\n",
       "4     TRAIN      0  227452       80.00\n",
       "5  VALIDATE      0   28431       10.00"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq.query(f\"\"\"\n",
    "SELECT splits, class,\n",
    "    count(*) as count,\n",
    "    ROUND(count(*) * 100.0 / SUM(count(*)) OVER (PARTITION BY class), 2) AS percentage\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
    "GROUP BY splits, class\n",
    "\"\"\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d723a989-0c74-43c0-9b20-b42ff209a47d",
   "metadata": {},
   "source": [
    "### Create The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "93462abf-d514-4f0d-a0f4-5a3a740c7347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e15001de-9964-40ad-bf84-c6d11fff8733",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created BigQuery Model:\n",
      "\tName: statmike-mlops-349915.mlops_serving.mlops-serving-bigquery-tensorflow-embedding_model\n",
      "\tGCS URI: gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/embedding_model\n",
      "\tTime (seconds): 12.267\n",
      "Created BigQuery Model:\n",
      "\tName: statmike-mlops-349915.mlops_serving.mlops-serving-bigquery-tensorflow-final_model\n",
      "\tGCS URI: gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/final_model\n",
      "\tTime (seconds): 12.761\n",
      "Created BigQuery Model:\n",
      "\tName: statmike-mlops-349915.mlops_serving.mlops-serving-bigquery-tensorflow-stacked_model\n",
      "\tGCS URI: gs://statmike-mlops-349915/mlops-serving/bigquery-tensorflow/models/stacked_model\n",
      "\tTime (seconds): 17.363\n"
     ]
    }
   ],
   "source": [
    "bq_models = []\n",
    "for model in models:\n",
    "    bq_model = f\"{BQ_PROJECT}.{BQ_DATASET}.{SERIES}-{EXPERIMENT}-{model.split('/')[-1]}\"\n",
    "    job = bq.query(f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{bq_model}`\n",
    "        OPTIONS(\n",
    "            MODEL_TYPE = 'TENSORFLOW',\n",
    "            MODEL_PATH = '{model}/*'\n",
    "        )\n",
    "    \"\"\")\n",
    "    job.result()\n",
    "    bq_models.append(bq_model)\n",
    "    print(f\"Created BigQuery Model:\\n\\tName: {bq_model}\\n\\tGCS URI: {model}\\n\\tTime (seconds): {(job.ended-job.started).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "11749f20-418a-4ff3-ac8d-64912fb83de0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['statmike-mlops-349915.mlops_serving.mlops-serving-bigquery-tensorflow-embedding_model',\n",
       " 'statmike-mlops-349915.mlops_serving.mlops-serving-bigquery-tensorflow-final_model',\n",
       " 'statmike-mlops-349915.mlops_serving.mlops-serving-bigquery-tensorflow-stacked_model']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab1f6e-2aee-411b-8416-8c7679a14530",
   "metadata": {},
   "source": [
    "### Predictions With ML.PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1f9b2049-009e-4dec-ab59-85e60f50b62a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 GET https://bigquery.googleapis.com/bigquery/v2/projects/statmike-mlops-349915/queries/b502b308-28ff-4234-b336-c502563c4ce7?maxResults=0&location=US&prettyPrint=false: Error when running TensorFlow SavedModel: {{function_node __inference_signature_wrapper_stateful_fn_105942}} {{function_node __inference_signature_wrapper_stateful_fn_105942}} Op type not registered 'XlaCallModule' in binary running on sandbox2. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n\t [[{{node StatefulPartitionedCall}}]]\n\t [[StatefulPartitionedCall_1]]\n\nLocation: US\nJob ID: b502b308-28ff-4234-b336-c502563c4ce7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[43mbq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43mSELECT *\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43mFROM ML.PREDICT (MODEL `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbq_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`,(\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m    SELECT features_array as input_layer #keras_tensor_113\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m    FROM `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBQ_PROJECT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBQ_DATASET\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBQ_TABLE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    WHERE splits = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTEST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m and class = 1\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    LIMIT 10)\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m  )\u001b[39;49m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:2057\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   1828\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1829\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1849\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   1850\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1852\u001b[0m \n\u001b[1;32m   1853\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;124;03m            :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2057\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[43mwait_for_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m query_result\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m   2059\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39mbqstorage_client,\n\u001b[1;32m   2060\u001b[0m         dtypes\u001b[38;5;241m=\u001b[39mdtypes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2074\u001b[0m         range_timestamp_dtype\u001b[38;5;241m=\u001b[39mrange_timestamp_dtype,\n\u001b[1;32m   2075\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_tqdm_helpers.py:107\u001b[0m, in \u001b[0;36mwait_for_query\u001b[0;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[1;32m    103\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m get_progress_bar(\n\u001b[1;32m    104\u001b[0m     progress_bar_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery is running\u001b[39m\u001b[38;5;124m\"\u001b[39m, default_total, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1681\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;66;03m# long-running API, don't delay the next request at all.\u001b[39;00m\n\u001b[0;32m-> 1681\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_job_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1682\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     \u001b[38;5;66;03m# Use a monotonic clock since we don't actually care about\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# daylight savings or similar, just the elapsed time.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1650\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.is_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;66;03m# Call jobs.getQueryResults with max results set to 0 just to\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;66;03m# wait for the query to finish. Unlike most methods,\u001b[39;00m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;66;03m# jobs.getQueryResults hangs as long as it can to ensure we\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;66;03m# know when the query has finished as soon as possible.\u001b[39;00m\n\u001b[0;32m-> 1650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reload_query_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mreload_query_results_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;66;03m# Even if the query is finished now according to\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;66;03m# jobs.getQueryResults, we'll want to reload the job status if\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m \u001b[38;5;66;03m# it's not already DONE.\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1448\u001b[0m, in \u001b[0;36mQueryJob._reload_query_results\u001b[0;34m(self, retry, timeout, page_size)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transport_timeout, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m   1446\u001b[0m         transport_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_query_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:2034\u001b[0m, in \u001b[0;36mClient._get_query_results\u001b[0;34m(self, job_id, retry, project, timeout_ms, location, timeout, page_size)\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;66;03m# This call is typically made in a polling loop that checks whether the\u001b[39;00m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;66;03m# job is complete (from QueryJob.done(), called ultimately from\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m \u001b[38;5;66;03m# QueryJob.result()). So we don't need to poll here.\u001b[39;00m\n\u001b[1;32m   2033\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[0;32m-> 2034\u001b[0m resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.getQueryResults\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2042\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _QueryResults\u001b[38;5;241m.\u001b[39mfrom_api_repr(resource)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:843\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[1;32m    841\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[1;32m    842\u001b[0m     ):\n\u001b[0;32m--> 843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/statmike-mlops-349915/queries/b502b308-28ff-4234-b336-c502563c4ce7?maxResults=0&location=US&prettyPrint=false: Error when running TensorFlow SavedModel: {{function_node __inference_signature_wrapper_stateful_fn_105942}} {{function_node __inference_signature_wrapper_stateful_fn_105942}} Op type not registered 'XlaCallModule' in binary running on sandbox2. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib (e.g. `tf.contrib.resampler`), accessing should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n\t [[{{node StatefulPartitionedCall}}]]\n\t [[StatefulPartitionedCall_1]]\n\nLocation: US\nJob ID: b502b308-28ff-4234-b336-c502563c4ce7\n"
     ]
    }
   ],
   "source": [
    "bq.query(f\"\"\"\n",
    "SELECT *\n",
    "FROM ML.PREDICT (MODEL `{bq_models[1]}`,(\n",
    "    SELECT features_array as input_layer #keras_tensor_113\n",
    "    FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
    "    WHERE splits = 'TEST' and class = 1\n",
    "    LIMIT 10)\n",
    "  )\n",
    "\"\"\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a08a7dd-fd11-49fc-ba18-b47df43735d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f90dff-64da-4e8f-94d1-9353fc5a150d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea826dfa-eef6-4089-9204-589b6a931edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d1c2c-49bd-466c-8d45-bc7c2e65287a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
